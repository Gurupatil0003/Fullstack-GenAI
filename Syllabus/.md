```python
import pandas as pd
from sklearn.cluster import KMeans ,DBSCAN,AgglomerativeClustering
df=pd.read_csv("/content/Mall_Customers (1).csv")

df.head(1)

X=df[["Annual Income (k$)","Spending Score (1-100)"]]

from sklearn.preprocessing import StandardScaler  
scaler=StandardScaler()
x_scaled=scaler.fit_transform(X)

import seaborn as sns
sns.scatterplot(x=X['Annual Income (k$)'],y=X['Spending Score (1-100)'],s=100)

model=DBSCAN()
cluster=model.fit_predict(x_scaled)

df['Cluster'] = cluster

sns.scatterplot(data=df, x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', palette='Set2', s=100)


from scipy.cluster.hierarchy import dendrogram, linkage
linked = linkage(X_scaled, method='ward')

dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=False)

```

```
import pandas as pd
df=pd.read_csv("/content/generated_dataset.csv")

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

p=PCA(n_components=2)
gg=p.fit_transform(df)

de=pd.DataFrame(gg,columns=['1','2'])
de.to_csv("f.csv")

```


```

# !pip install mlxtend

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

# Load your dataset
df = pd.read_csv('groceries.csv')

# Convert each transaction row into a list of items (drop NaNs)
transactions = df.apply(lambda row: row.dropna().tolist(), axis=1).tolist()

# One-hot encode the transactions
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

# Find frequent itemsets
frequent_items = apriori(df_encoded, min_support=0.03, use_colnames=True)

# Generate association rules
rules = association_rules(frequent_items, metric="confidence", min_threshold=0.3)

# Display top rules
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False).head(10))
```
