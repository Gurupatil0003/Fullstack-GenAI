```python
import pandas as pd
from sklearn.cluster import KMeans ,DBSCAN,AgglomerativeClustering
df=pd.read_csv("/content/Mall_Customers (1).csv")

df.head(1)

X=df[["Annual Income (k$)","Spending Score (1-100)"]]

from sklearn.preprocessing import StandardScaler  
scaler=StandardScaler()
x_scaled=scaler.fit_transform(X)

import seaborn as sns
sns.scatterplot(x=X['Annual Income (k$)'],y=X['Spending Score (1-100)'],s=100)

model=DBSCAN()
cluster=model.fit_predict(x_scaled)

df['Cluster'] = cluster

sns.scatterplot(data=df, x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', palette='Set2', s=100)


from scipy.cluster.hierarchy import dendrogram, linkage
linked = linkage(X_scaled, method='ward')

dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=False)

```

```
import pandas as pd
df=pd.read_csv("/content/generated_dataset.csv")

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

p=PCA(n_components=2)
gg=p.fit_transform(df)

de=pd.DataFrame(gg,columns=['1','2'])
de.to_csv("f.csv")

```


```

# !pip install mlxtend

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

# Load your dataset
df = pd.read_csv('groceries.csv')

# Convert each transaction row into a list of items (drop NaNs)
transactions = df.apply(lambda row: row.dropna().tolist(), axis=1).tolist()

# One-hot encode the transactions
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

# Find frequent itemsets
frequent_items = apriori(df_encoded, min_support=0.03, use_colnames=True)

# Generate association rules
rules = association_rules(frequent_items, metric="confidence", min_threshold=0.3)

# Display top rules
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False).head(10))
```

~~~python
import os
from PIL import Image as PILImage
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.media import Image as AgnoImage
import gradio as gr

# Load Google API Key
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Prompt for medical image analysis
query = """
You are a highly skilled medical imaging expert with extensive knowledge in radiology and diagnostic imaging. Analyze the patient's medical image and structure your response as follows:

### 1. Image Type & Region
- Specify imaging modality (X-ray/MRI/CT/Ultrasound/etc.)
- Identify the patient's anatomical region and positioning
- Comment on image quality and technical adequacy

### 2. Key Findings
- List primary observations systematically
- Note any abnormalities in the patient's imaging with precise descriptions
- Include measurements and densities where relevant
- Describe location, size, shape, and characteristics
- Rate severity: Normal/Mild/Moderate/Severe

### 3. Diagnostic Assessment
- Provide primary diagnosis with confidence level
- List differential diagnoses in order of likelihood
- Support each diagnosis with observed evidence from the patient's imaging
- Note any critical or urgent findings

### 4. Patient-Friendly Explanation
- Explain the findings in simple, clear language that the patient can understand
- Avoid medical jargon or provide clear definitions
- Include visual analogies if helpful
- Address common patient concerns related to these findings

### 5. Research Context
IMPORTANT: Use the DuckDuckGo search tool to:
- Find recent medical literature about similar cases
- Search for standard treatment protocols
- Provide a list of relevant medical links of them too
- Research any relevant technological advances
- Include 2-3 key references to support your analysis

Format your response using clear markdown headers and bullet points. Be concise yet thorough.
"""

# Image analysis function
def analyze_medical_image(api_key, image_np):
    if not api_key:
        return "‚ùå Please provide a valid Google API key."

    # Initialize the agent
    agent = Agent(
        model=Gemini(id="gemini-2.0-flash", api_key=api_key),
        tools=[DuckDuckGoTools()],
        markdown=True
    )

    # Resize image
    img = PILImage.fromarray(image_np)
    img = img.resize((500, int(500 / img.width * img.height)))
    temp_path = "temp_image.png"
    img.save(temp_path)


    # Analyze with Gemini + DuckDuckGo
    agno_img = AgnoImage(filepath=temp_path)
    result = agent.run(query, images=[agno_img])

    return result.content


# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("## üè• Medical Imaging Diagnosis Agent")
    gr.Markdown("Upload a medical image to receive an AI-generated analysis report.\n\n‚ö†Ô∏è **Disclaimer:** Educational use only. Not a clinical diagnosis tool.")

    api_input = gr.Textbox(label="üîë Google API Key", type="password", placeholder="Paste your API key")
    image_input = gr.Image(label="üñºÔ∏è Upload Medical Image", type="numpy")
    analyze_button = gr.Button("üîç Analyze")
    output_md = gr.Markdown()

    analyze_button.click(analyze_medical_image, inputs=[api_input, image_input], outputs=output_md)

demo.launch()
~~~
